{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd0f3aabb56ceede8bbce4061734790a50077821e4e2e3353160b6deb4f0667efe9",
   "display_name": "Python 3.7.7 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "f3aabb56ceede8bbce4061734790a50077821e4e2e3353160b6deb4f0667efe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import kerastuner as kt"
   ]
  },
  {
   "source": [
    "The model must have:\n",
    "\n",
    "3 convolutional blocks with a number of filters of respectively 16, 32, and 64; each block containing:\n",
    "\n",
    "A Conv2D layer with a ReLU activation.\n",
    "A Max Pooling layer (2,2 pool size)\n",
    "A dense layer with 28 hidden units.\n",
    "\n",
    "A dense output layer with a softmax activation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "((x_train, y_train), (x_test, y_test)) = keras.datasets.fashion_mnist.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_shape = x_train[0].shape\n",
    "img_width, img_height = sample_shape[0], sample_shape[1]\n",
    "input_shape = (img_width, img_height, 1)\n",
    "\n",
    "# Reshape data \n",
    "x_train = x_train.reshape(len(x_train), input_shape[0], input_shape[1], input_shape[2])\n",
    "x_test  = x_test.reshape(len(x_test), input_shape[0], input_shape[1], input_shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=================] - 9s 5ms/step - loss: 0.2620 - accuracy: 0.9021\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2546 - accuracy: 0.9049\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2419 - accuracy: 0.9104\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2367 - accuracy: 0.9115\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2322 - accuracy: 0.9134\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2286 - accuracy: 0.9144\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2237 - accuracy: 0.9161\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2165 - accuracy: 0.9176\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2161 - accuracy: 0.9199\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2097 - accuracy: 0.9220\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2045 - accuracy: 0.9225\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2035 - accuracy: 0.9229\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1994 - accuracy: 0.9260\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1957 - accuracy: 0.9269\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1895 - accuracy: 0.9280\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1906 - accuracy: 0.9275\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1870 - accuracy: 0.9292\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1795 - accuracy: 0.9323\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1826 - accuracy: 0.9322\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1838 - accuracy: 0.9308\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1782 - accuracy: 0.9339\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1715 - accuracy: 0.9352\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1704 - accuracy: 0.9361\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1707 - accuracy: 0.9359\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1670 - accuracy: 0.9368\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1674 - accuracy: 0.9368\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1653 - accuracy: 0.9383\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1638 - accuracy: 0.9384\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1559 - accuracy: 0.9415\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1562 - accuracy: 0.9413\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1595 - accuracy: 0.9405\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1555 - accuracy: 0.9418\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1534 - accuracy: 0.9435\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1544 - accuracy: 0.9434\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1512 - accuracy: 0.9439\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1499 - accuracy: 0.9444\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1494 - accuracy: 0.9445\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1490 - accuracy: 0.9439\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1513 - accuracy: 0.9453\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1461 - accuracy: 0.9459\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1450 - accuracy: 0.9467\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1439 - accuracy: 0.9470\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1447 - accuracy: 0.9471\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1386 - accuracy: 0.9488\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1470 - accuracy: 0.9468\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1394 - accuracy: 0.9478\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1419 - accuracy: 0.9485\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1381 - accuracy: 0.9489\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1361 - accuracy: 0.9500\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1358 - accuracy: 0.9505\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1331 - accuracy: 0.9514\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1352 - accuracy: 0.9505\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1311 - accuracy: 0.9516\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1319 - accuracy: 0.9520\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1376 - accuracy: 0.9499\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1260 - accuracy: 0.9544\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1255 - accuracy: 0.9536\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1320 - accuracy: 0.9528\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1284 - accuracy: 0.9535\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1283 - accuracy: 0.9534\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1250 - accuracy: 0.9545\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1318 - accuracy: 0.9530\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1242 - accuracy: 0.9542\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1293 - accuracy: 0.9532\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1193 - accuracy: 0.9557\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1289 - accuracy: 0.9544\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1265 - accuracy: 0.9548\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1183 - accuracy: 0.9567\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1274 - accuracy: 0.9537\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1208 - accuracy: 0.9567\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1206 - accuracy: 0.9571\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1245 - accuracy: 0.9560\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1264 - accuracy: 0.9555\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1262 - accuracy: 0.9555\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1188 - accuracy: 0.9570\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1128 - accuracy: 0.9600\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1278 - accuracy: 0.9549\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1215 - accuracy: 0.9565\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1133 - accuracy: 0.9587\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1125 - accuracy: 0.9596\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1252 - accuracy: 0.9552\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1131 - accuracy: 0.9586\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1311 - accuracy: 0.9545\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1120 - accuracy: 0.9596\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1050 - accuracy: 0.9623\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1243 - accuracy: 0.9572\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1050 - accuracy: 0.9627\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1274 - accuracy: 0.9545\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1145 - accuracy: 0.9589\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1035 - accuracy: 0.9623\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1398 - accuracy: 0.9543\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.7818 - accuracy: 0.8692\n",
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 1.2946 - accuracy: 0.5963\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.6147 - accuracy: 0.7786\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.5334 - accuracy: 0.8067\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4836 - accuracy: 0.8234\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4513 - accuracy: 0.8350\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4217 - accuracy: 0.8461\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4012 - accuracy: 0.8541\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3809 - accuracy: 0.8608\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3645 - accuracy: 0.8676\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3523 - accuracy: 0.8714\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3399 - accuracy: 0.8755\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3305 - accuracy: 0.8798\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3206 - accuracy: 0.8827\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3109 - accuracy: 0.8865\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3029 - accuracy: 0.8898\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2954 - accuracy: 0.8923\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2859 - accuracy: 0.8956\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2809 - accuracy: 0.8977\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2748 - accuracy: 0.8995\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2677 - accuracy: 0.9019\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2614 - accuracy: 0.9043\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2575 - accuracy: 0.9057\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2507 - accuracy: 0.9088\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2460 - accuracy: 0.9097\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2406 - accuracy: 0.9113\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2355 - accuracy: 0.9137\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2316 - accuracy: 0.9152\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2267 - accuracy: 0.9168\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2226 - accuracy: 0.9191\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2188 - accuracy: 0.9188\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2145 - accuracy: 0.9222\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2108 - accuracy: 0.9227\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2066 - accuracy: 0.9247\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2029 - accuracy: 0.9251\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1994 - accuracy: 0.9266\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1976 - accuracy: 0.9275\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1927 - accuracy: 0.9293\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1892 - accuracy: 0.9308\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1872 - accuracy: 0.9316\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1848 - accuracy: 0.9323\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1799 - accuracy: 0.9345\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1781 - accuracy: 0.9355\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1744 - accuracy: 0.9367\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1727 - accuracy: 0.9374\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1695 - accuracy: 0.9374\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1669 - accuracy: 0.9395\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1640 - accuracy: 0.9391\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1621 - accuracy: 0.9417\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1590 - accuracy: 0.9410\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1575 - accuracy: 0.9430\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1553 - accuracy: 0.9442\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1523 - accuracy: 0.9446\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1522 - accuracy: 0.9450\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1477 - accuracy: 0.9465\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1458 - accuracy: 0.9466\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1440 - accuracy: 0.9480\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1419 - accuracy: 0.9493\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1392 - accuracy: 0.9494\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1381 - accuracy: 0.9491\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1358 - accuracy: 0.9504\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1328 - accuracy: 0.9518\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1309 - accuracy: 0.9524\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1287 - accuracy: 0.9538\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1284 - accuracy: 0.9527\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1269 - accuracy: 0.9542\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1242 - accuracy: 0.9554\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1217 - accuracy: 0.9556\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1209 - accuracy: 0.9565\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1202 - accuracy: 0.9569\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1172 - accuracy: 0.9574\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1145 - accuracy: 0.9584\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1128 - accuracy: 0.9598\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1128 - accuracy: 0.9595\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1105 - accuracy: 0.9604\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1094 - accuracy: 0.9604\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1068 - accuracy: 0.9615\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1051 - accuracy: 0.9619\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1044 - accuracy: 0.9624\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1028 - accuracy: 0.9635\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1018 - accuracy: 0.9630\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0998 - accuracy: 0.9640\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0991 - accuracy: 0.9647\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0968 - accuracy: 0.9648\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0965 - accuracy: 0.9654\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0957 - accuracy: 0.9658\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0946 - accuracy: 0.9660\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0930 - accuracy: 0.9668\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0910 - accuracy: 0.9669\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0912 - accuracy: 0.9666\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0882 - accuracy: 0.9690\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0881 - accuracy: 0.9692\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0869 - accuracy: 0.9689\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0866 - accuracy: 0.9689\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0826 - accuracy: 0.9707\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0839 - accuracy: 0.9705\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0821 - accuracy: 0.9709\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0803 - accuracy: 0.9720\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0817 - accuracy: 0.9713\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0796 - accuracy: 0.9716\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0784 - accuracy: 0.9723\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.7291 - accuracy: 0.8662\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"learning_rate\",\"test_accuracy\"])\n",
    "c = 0\n",
    "for i in [1e-2, 1e-3, 1e-4]:\n",
    "    c += 1\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(28,28,1)))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3),activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(tf.keras.layers.Conv2D(activation=\"relu\", filters=32, kernel_size=(3,3)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(tf.keras.layers.Conv2D(activation=\"relu\", filters=64, kernel_size=(3,3)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(28, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(10,activation=\"softmax\"))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=i),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "    model.fit(x_train,y_train, batch_size=32,epochs=100)\n",
    "    test_score, test_acc = model.evaluate(x_test, y_test)\n",
    "    df.loc[c] = [i, test_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   learning_rate  test_accuracy\n",
       "1         0.0100         0.6943\n",
       "2         0.0010         0.8692\n",
       "3         0.0001         0.8662"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>learning_rate</th>\n      <th>test_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.0100</td>\n      <td>0.6943</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0010</td>\n      <td>0.8692</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0001</td>\n      <td>0.8662</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/25\n",
      " 272/1875 [===>..........................] - ETA: 8s - loss: 1.2640 - accuracy: 0.6542"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-f0877d325c83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"softmax\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mtest_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(28,28,1)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3),activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(activation=\"relu\", filters=32, kernel_size=(3,3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(activation=\"relu\", filters=64, kernel_size=(3,3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(28, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10,activation=\"softmax\"))\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.fit(x_train,y_train, batch_size=32,epochs=25)\n",
    "test_score, test_acc = model.evaluate(x_test, y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   nb_epochs  test_accuracy\n",
       "3       50.0         0.8645"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nb_epochs</th>\n      <th>test_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>50.0</td>\n      <td>0.8645</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}