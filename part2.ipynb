{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd0f3aabb56ceede8bbce4061734790a50077821e4e2e3353160b6deb4f0667efe9",
   "display_name": "Python 3.7.7 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "f3aabb56ceede8bbce4061734790a50077821e4e2e3353160b6deb4f0667efe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "((x_train, y_train), (x_test, y_test)) = keras.datasets.fashion_mnist.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "source": [
    "# Question 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(28,28)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(10,activation=\"softmax\",kernel_initializer=\"random_normal\", bias_initializer=\"random_normal\"))\n",
    "opt = keras.optimizers.Adam(learning_rate=10**(-5))\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "source": [
    "# Question 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 1s 471us/step - loss: 75.4622 - categorical_accuracy: 0.3103\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 1s 488us/step - loss: 31.0503 - categorical_accuracy: 0.5460\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 1s 500us/step - loss: 23.6103 - categorical_accuracy: 0.6184\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 1s 489us/step - loss: 19.8980 - categorical_accuracy: 0.6554\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 1s 489us/step - loss: 17.6199 - categorical_accuracy: 0.6781\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 1s 470us/step - loss: 16.0472 - categorical_accuracy: 0.6940\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 1s 471us/step - loss: 14.8782 - categorical_accuracy: 0.7080\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 1s 458us/step - loss: 13.9330 - categorical_accuracy: 0.7183\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 1s 467us/step - loss: 13.1841 - categorical_accuracy: 0.7268\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 1s 457us/step - loss: 12.5365 - categorical_accuracy: 0.7330\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 1s 461us/step - loss: 11.9770 - categorical_accuracy: 0.7395\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 1s 459us/step - loss: 11.5052 - categorical_accuracy: 0.7449\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 1s 460us/step - loss: 11.0815 - categorical_accuracy: 0.7495\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 1s 461us/step - loss: 10.7016 - categorical_accuracy: 0.7527\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 1s 456us/step - loss: 10.3700 - categorical_accuracy: 0.7553\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 1s 458us/step - loss: 10.0544 - categorical_accuracy: 0.7588\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 1s 458us/step - loss: 9.7756 - categorical_accuracy: 0.7625\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 1s 465us/step - loss: 9.5099 - categorical_accuracy: 0.7637\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 1s 454us/step - loss: 9.2725 - categorical_accuracy: 0.7657\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 1s 456us/step - loss: 9.0429 - categorical_accuracy: 0.7679\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 1s 458us/step - loss: 8.8273 - categorical_accuracy: 0.7701\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 1s 468us/step - loss: 8.6448 - categorical_accuracy: 0.7716\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 1s 458us/step - loss: 8.4568 - categorical_accuracy: 0.7733\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 1s 460us/step - loss: 8.2841 - categorical_accuracy: 0.7749\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 1s 460us/step - loss: 8.1190 - categorical_accuracy: 0.7764\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 1s 470us/step - loss: 7.9726 - categorical_accuracy: 0.7772\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 1s 457us/step - loss: 7.8209 - categorical_accuracy: 0.7791\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 1s 459us/step - loss: 7.6833 - categorical_accuracy: 0.7801\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 1s 459us/step - loss: 7.5541 - categorical_accuracy: 0.7815\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 1s 461us/step - loss: 7.4344 - categorical_accuracy: 0.7817\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 1s 458us/step - loss: 7.3060 - categorical_accuracy: 0.7837\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 1s 459us/step - loss: 7.1970 - categorical_accuracy: 0.7837\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 1s 457us/step - loss: 7.0838 - categorical_accuracy: 0.7846\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 1s 457us/step - loss: 6.9766 - categorical_accuracy: 0.7856\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 1s 457us/step - loss: 6.8746 - categorical_accuracy: 0.7872\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 1s 455us/step - loss: 6.7733 - categorical_accuracy: 0.7880\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 1s 486us/step - loss: 6.6800 - categorical_accuracy: 0.7879\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 1s 476us/step - loss: 6.5960 - categorical_accuracy: 0.7887\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 1s 472us/step - loss: 6.5034 - categorical_accuracy: 0.7894\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 1s 489us/step - loss: 6.4193 - categorical_accuracy: 0.7903\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 1s 465us/step - loss: 6.3385 - categorical_accuracy: 0.7904\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 1s 461us/step - loss: 6.2541 - categorical_accuracy: 0.7912\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 1s 477us/step - loss: 6.1803 - categorical_accuracy: 0.7927\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 1s 469us/step - loss: 6.0954 - categorical_accuracy: 0.7935\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 1s 470us/step - loss: 6.0360 - categorical_accuracy: 0.7934\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 1s 446us/step - loss: 5.9672 - categorical_accuracy: 0.7939\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 1s 456us/step - loss: 5.8966 - categorical_accuracy: 0.7947\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 1s 478us/step - loss: 5.8253 - categorical_accuracy: 0.7952\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 1s 471us/step - loss: 5.7597 - categorical_accuracy: 0.7969\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 1s 470us/step - loss: 5.6974 - categorical_accuracy: 0.7966\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 1s 459us/step - loss: 5.6417 - categorical_accuracy: 0.7972\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 1s 468us/step - loss: 5.5740 - categorical_accuracy: 0.7973\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 1s 463us/step - loss: 5.5130 - categorical_accuracy: 0.7981\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 1s 445us/step - loss: 5.4580 - categorical_accuracy: 0.7982\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 1s 445us/step - loss: 5.4044 - categorical_accuracy: 0.7990\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 1s 444us/step - loss: 5.3448 - categorical_accuracy: 0.7992\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 1s 459us/step - loss: 5.2932 - categorical_accuracy: 0.8001\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 1s 474us/step - loss: 5.2413 - categorical_accuracy: 0.8003\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 1s 469us/step - loss: 5.1862 - categorical_accuracy: 0.8012\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 1s 465us/step - loss: 5.1341 - categorical_accuracy: 0.8012\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 1s 468us/step - loss: 5.0897 - categorical_accuracy: 0.8010\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 1s 471us/step - loss: 5.0434 - categorical_accuracy: 0.8014\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 1s 453us/step - loss: 4.9896 - categorical_accuracy: 0.8023\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 1s 464us/step - loss: 4.9422 - categorical_accuracy: 0.8029\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 1s 461us/step - loss: 4.9036 - categorical_accuracy: 0.8033\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 1s 461us/step - loss: 4.8556 - categorical_accuracy: 0.8029\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 1s 471us/step - loss: 4.8128 - categorical_accuracy: 0.8032\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 1s 460us/step - loss: 4.7695 - categorical_accuracy: 0.8045\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 1s 458us/step - loss: 4.7325 - categorical_accuracy: 0.8036\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 1s 459us/step - loss: 4.6818 - categorical_accuracy: 0.8042\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 1s 460us/step - loss: 4.6473 - categorical_accuracy: 0.8050\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 1s 461us/step - loss: 4.6041 - categorical_accuracy: 0.8055\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 1s 458us/step - loss: 4.5602 - categorical_accuracy: 0.8051\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 1s 458us/step - loss: 4.5288 - categorical_accuracy: 0.8048\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 1s 467us/step - loss: 4.4870 - categorical_accuracy: 0.8062\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 1s 459us/step - loss: 4.4488 - categorical_accuracy: 0.8067\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 1s 457us/step - loss: 4.4157 - categorical_accuracy: 0.8054\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 1s 463us/step - loss: 4.3749 - categorical_accuracy: 0.8062\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 1s 458us/step - loss: 4.3425 - categorical_accuracy: 0.8065\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 1s 460us/step - loss: 4.3057 - categorical_accuracy: 0.8071\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 1s 460us/step - loss: 4.2703 - categorical_accuracy: 0.8068\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 1s 460us/step - loss: 4.2437 - categorical_accuracy: 0.8075\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 1s 460us/step - loss: 4.2081 - categorical_accuracy: 0.8091\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 1s 466us/step - loss: 4.1714 - categorical_accuracy: 0.8074\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 1s 460us/step - loss: 4.1373 - categorical_accuracy: 0.8090\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 1s 455us/step - loss: 4.1063 - categorical_accuracy: 0.8082\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 1s 459us/step - loss: 4.0762 - categorical_accuracy: 0.8090\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 1s 456us/step - loss: 4.0431 - categorical_accuracy: 0.8098\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 1s 469us/step - loss: 4.0043 - categorical_accuracy: 0.8098\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 1s 474us/step - loss: 3.9836 - categorical_accuracy: 0.8100\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 1s 465us/step - loss: 3.9462 - categorical_accuracy: 0.8099\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 1s 469us/step - loss: 3.9232 - categorical_accuracy: 0.8097\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 1s 456us/step - loss: 3.8954 - categorical_accuracy: 0.8106\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 1s 460us/step - loss: 3.8617 - categorical_accuracy: 0.8102\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 1s 476us/step - loss: 3.8357 - categorical_accuracy: 0.8111\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 1s 477us/step - loss: 3.8077 - categorical_accuracy: 0.8105\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 1s 472us/step - loss: 3.7788 - categorical_accuracy: 0.8116\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 1s 471us/step - loss: 3.7475 - categorical_accuracy: 0.8115\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 1s 482us/step - loss: 3.7215 - categorical_accuracy: 0.8115\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 1s 468us/step - loss: 3.6992 - categorical_accuracy: 0.8110\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=100)\n",
    "model.save(\"./models/2q2.model\", save_format=\"h5\")"
   ]
  },
  {
   "source": [
    "# Question 3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_25 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1875/1875 [==============================] - 1s 340us/step - loss: 3.6959 - categorical_accuracy: 0.8084\n",
      "  1/313 [..............................] - ETA: 0s - loss: 5.5192 - categorical_accuracy: 0.7188WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "313/313 [==============================] - 0s 603us/step - loss: 4.9924 - categorical_accuracy: 0.7818\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "train_score, train_acc = model.evaluate(x_train, y_train)\n",
    "test_score, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "source": [
    "# Question 4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.Sequential()\n",
    "model1.add(tf.keras.Input(shape=(28,28)))\n",
    "model1.add(tf.keras.layers.Flatten())\n",
    "model1.add(tf.keras.layers.Dense(100,activation=\"tanh\",kernel_initializer=\"random_normal\", bias_initializer=\"random_normal\"))\n",
    "model1.add(tf.keras.layers.Dense(10,activation=\"softmax\",kernel_initializer=\"random_normal\", bias_initializer=\"random_normal\"))\n",
    "opt1 = keras.optimizers.Adam(learning_rate=10**(-5))\n",
    "model1.compile(optimizer=opt1, loss=\"categorical_crossentropy\", metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "source": [
    "# Question 5"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 1s 613us/step - loss: 1.8819 - categorical_accuracy: 0.4248\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 1s 597us/step - loss: 1.3659 - categorical_accuracy: 0.6328\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 1s 584us/step - loss: 1.1257 - categorical_accuracy: 0.6735\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 1s 603us/step - loss: 0.9788 - categorical_accuracy: 0.6969\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 1s 582us/step - loss: 0.8795 - categorical_accuracy: 0.7154\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 1s 583us/step - loss: 0.8089 - categorical_accuracy: 0.7315\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 1s 583us/step - loss: 0.7574 - categorical_accuracy: 0.7455\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 1s 582us/step - loss: 0.7187 - categorical_accuracy: 0.7550\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 1s 595us/step - loss: 0.6867 - categorical_accuracy: 0.7643\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 1s 582us/step - loss: 0.6609 - categorical_accuracy: 0.7719\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 1s 597us/step - loss: 0.6406 - categorical_accuracy: 0.7796\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 1s 587us/step - loss: 0.6220 - categorical_accuracy: 0.7856\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 1s 592us/step - loss: 0.6072 - categorical_accuracy: 0.7869\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 1s 592us/step - loss: 0.5926 - categorical_accuracy: 0.7915\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 1s 581us/step - loss: 0.5801 - categorical_accuracy: 0.7983\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 1s 587us/step - loss: 0.5692 - categorical_accuracy: 0.8013\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 1s 587us/step - loss: 0.5594 - categorical_accuracy: 0.8053\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 1s 579us/step - loss: 0.5495 - categorical_accuracy: 0.8070\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 1s 587us/step - loss: 0.5416 - categorical_accuracy: 0.8109\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 1s 585us/step - loss: 0.5339 - categorical_accuracy: 0.8125\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 1s 587us/step - loss: 0.5272 - categorical_accuracy: 0.8141\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 1s 618us/step - loss: 0.5211 - categorical_accuracy: 0.8166\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 1s 596us/step - loss: 0.5137 - categorical_accuracy: 0.8189\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 1s 621us/step - loss: 0.5094 - categorical_accuracy: 0.8197\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 1s 608us/step - loss: 0.5041 - categorical_accuracy: 0.8218\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 1s 591us/step - loss: 0.4977 - categorical_accuracy: 0.8250\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 1s 592us/step - loss: 0.4932 - categorical_accuracy: 0.8249\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 1s 619us/step - loss: 0.4894 - categorical_accuracy: 0.8266\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 1s 595us/step - loss: 0.4856 - categorical_accuracy: 0.8281\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 1s 590us/step - loss: 0.4808 - categorical_accuracy: 0.8291\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 1s 598us/step - loss: 0.4762 - categorical_accuracy: 0.8304\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 1s 598us/step - loss: 0.4734 - categorical_accuracy: 0.8312\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 1s 591us/step - loss: 0.4696 - categorical_accuracy: 0.8316\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 1s 601us/step - loss: 0.4649 - categorical_accuracy: 0.8352\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 1s 593us/step - loss: 0.4621 - categorical_accuracy: 0.8357\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 1s 595us/step - loss: 0.4589 - categorical_accuracy: 0.8361\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 1s 605us/step - loss: 0.4559 - categorical_accuracy: 0.8366\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 1s 593us/step - loss: 0.4540 - categorical_accuracy: 0.8389\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 1s 589us/step - loss: 0.4519 - categorical_accuracy: 0.8392\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 1s 589us/step - loss: 0.4490 - categorical_accuracy: 0.8397\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 1s 600us/step - loss: 0.4464 - categorical_accuracy: 0.8394\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 1s 609us/step - loss: 0.4444 - categorical_accuracy: 0.8414\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 1s 618us/step - loss: 0.4403 - categorical_accuracy: 0.8439\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 1s 648us/step - loss: 0.4384 - categorical_accuracy: 0.8439\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 1s 664us/step - loss: 0.4352 - categorical_accuracy: 0.8453\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 1s 685us/step - loss: 0.4347 - categorical_accuracy: 0.8453\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 1s 617us/step - loss: 0.4313 - categorical_accuracy: 0.8464\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 1s 604us/step - loss: 0.4289 - categorical_accuracy: 0.8471\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 1s 602us/step - loss: 0.4267 - categorical_accuracy: 0.8481\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 1s 630us/step - loss: 0.4242 - categorical_accuracy: 0.8490\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 1s 604us/step - loss: 0.4238 - categorical_accuracy: 0.8487\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 1s 609us/step - loss: 0.4215 - categorical_accuracy: 0.8487\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 1s 615us/step - loss: 0.4193 - categorical_accuracy: 0.8498\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 1s 602us/step - loss: 0.4175 - categorical_accuracy: 0.8513\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 1s 601us/step - loss: 0.4165 - categorical_accuracy: 0.8511\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 1s 601us/step - loss: 0.4141 - categorical_accuracy: 0.8521\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 1s 600us/step - loss: 0.4123 - categorical_accuracy: 0.8529\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 1s 597us/step - loss: 0.4114 - categorical_accuracy: 0.8539\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 1s 599us/step - loss: 0.4073 - categorical_accuracy: 0.8551\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 1s 602us/step - loss: 0.4074 - categorical_accuracy: 0.8537\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 1s 617us/step - loss: 0.4059 - categorical_accuracy: 0.8553\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 1s 598us/step - loss: 0.4037 - categorical_accuracy: 0.8564\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 1s 599us/step - loss: 0.4018 - categorical_accuracy: 0.8565\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 1s 598us/step - loss: 0.4000 - categorical_accuracy: 0.8573\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 1s 600us/step - loss: 0.3981 - categorical_accuracy: 0.8579\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 1s 601us/step - loss: 0.3974 - categorical_accuracy: 0.8587\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 1s 600us/step - loss: 0.3943 - categorical_accuracy: 0.8604\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 1s 616us/step - loss: 0.3937 - categorical_accuracy: 0.8597\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 1s 599us/step - loss: 0.3930 - categorical_accuracy: 0.8608\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 1s 597us/step - loss: 0.3887 - categorical_accuracy: 0.8613\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 1s 599us/step - loss: 0.3874 - categorical_accuracy: 0.8620\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 1s 596us/step - loss: 0.3890 - categorical_accuracy: 0.8614\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 1s 600us/step - loss: 0.3892 - categorical_accuracy: 0.8616\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 1s 604us/step - loss: 0.3869 - categorical_accuracy: 0.8625\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 1s 613us/step - loss: 0.3850 - categorical_accuracy: 0.8626\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 1s 614us/step - loss: 0.3841 - categorical_accuracy: 0.8626\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 1s 604us/step - loss: 0.3810 - categorical_accuracy: 0.8634\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 1s 606us/step - loss: 0.3814 - categorical_accuracy: 0.8640\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 1s 604us/step - loss: 0.3804 - categorical_accuracy: 0.8641\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 1s 604us/step - loss: 0.3789 - categorical_accuracy: 0.8649\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 1s 607us/step - loss: 0.3766 - categorical_accuracy: 0.8664\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 1s 617us/step - loss: 0.3773 - categorical_accuracy: 0.8651\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 1s 617us/step - loss: 0.3765 - categorical_accuracy: 0.8656\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 1s 603us/step - loss: 0.3737 - categorical_accuracy: 0.8676\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 1s 602us/step - loss: 0.3724 - categorical_accuracy: 0.8679\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 1s 605us/step - loss: 0.3709 - categorical_accuracy: 0.8680\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 1s 622us/step - loss: 0.3701 - categorical_accuracy: 0.8681\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 1s 637us/step - loss: 0.3698 - categorical_accuracy: 0.8681\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 1s 638us/step - loss: 0.3690 - categorical_accuracy: 0.8683\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 1s 613us/step - loss: 0.3695 - categorical_accuracy: 0.8681\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 1s 614us/step - loss: 0.3657 - categorical_accuracy: 0.8698\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 1s 638us/step - loss: 0.3638 - categorical_accuracy: 0.8711\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 1s 668us/step - loss: 0.3627 - categorical_accuracy: 0.8705\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 1s 671us/step - loss: 0.3641 - categorical_accuracy: 0.8708\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 1s 607us/step - loss: 0.3613 - categorical_accuracy: 0.8719\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 1s 609us/step - loss: 0.3624 - categorical_accuracy: 0.8712\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 1s 595us/step - loss: 0.3606 - categorical_accuracy: 0.8723\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 1s 587us/step - loss: 0.3596 - categorical_accuracy: 0.8727\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 1s 586us/step - loss: 0.3599 - categorical_accuracy: 0.8730\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 1s 587us/step - loss: 0.3601 - categorical_accuracy: 0.8716\n"
     ]
    }
   ],
   "source": [
    "model1.fit(x_train, y_train, batch_size=32, epochs=100)\n",
    "model1.save(\"./models/2q4.model\", save_format=\"h5\")"
   ]
  },
  {
   "source": [
    "# Question 6"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_26 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1875/1875 [==============================] - 1s 402us/step - loss: 0.3567 - categorical_accuracy: 0.8731\n",
      "313/313 [==============================] - 0s 623us/step - loss: 0.4422 - categorical_accuracy: 0.8417\n"
     ]
    }
   ],
   "source": [
    "model1.summary()\n",
    "train_score1, train_acc1 = model1.evaluate(x_train, y_train)\n",
    "test_score1, test_acc1 = model1.evaluate(x_test, y_test)"
   ]
  },
  {
   "source": [
    "# Question 7"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.4416 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1875/1875 [==============================] - 1s 597us/step - loss: 1.9173 - accuracy: 0.3827\n",
      "Epoch 2/100\n",
      "1739/1875 [==========================>...] - ETA: 0s - loss: 1.4336 - accuracy: 0.6018"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-826a53ca3a0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mopt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mtest_score2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_acc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"activation fct\",\"mean acc\"])\n",
    "c = 0\n",
    "for i in [\"tanh\",\"relu\"]:\n",
    "    c += 1\n",
    "    tmp = []\n",
    "    for _ in range(10):\n",
    "        model2 = tf.keras.Sequential()\n",
    "        model2.add(tf.keras.Input(shape=(28,28)))\n",
    "        model2.add(tf.keras.layers.Flatten())\n",
    "        model2.add(tf.keras.layers.Dense(100,activation=i,kernel_initializer=\"random_normal\", bias_initializer=\"random_normal\"))\n",
    "        model2.add(tf.keras.layers.Dense(10,activation=\"softmax\",kernel_initializer=\"random_normal\", bias_initializer=\"random_normal\"))\n",
    "        opt2 = keras.optimizers.Adam(learning_rate=10**(-5))\n",
    "        model2.compile(optimizer=opt2, loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "        model2.fit(x_train, y_train, batch_size=32, epochs=100)\n",
    "        test_score2, test_acc2 = model2.evaluate(x_test, y_test)\n",
    "        tmp.append(test_acc2)\n",
    "    df.loc[c] = [i, np.mean(tmp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}